{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dea1a87-709b-4621-b6cd-5eca9fdef2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "print(device)\n",
    "block_size=8\n",
    "batch_size=4\n",
    "max_iters = 1000\n",
    "# eval_interval = 2500\n",
    "learning_rate = 3e-2\n",
    "eval_iters = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22a9f13-62d7-4303-bea1-54ef0b01a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿  DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "  BY\n",
      "\n",
      "  L. FRANK BAUM\n",
      "\n",
      "  AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
      "\n",
      "  ILLUSTRATED BY JOHN R. NEILL\n",
      "\n",
      "  BOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text=f.read()\n",
    "\n",
    "print(text[:200])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2928907-0fad-4b1d-8c3c-6e5201bad046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(set(text))\n",
    "print(chars)\n",
    "print(len(chars))\n",
    "vocab_size=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da51324-ad68-4507-9380-78ed1ff6762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 58, 65, 65, 68]\n"
     ]
    }
   ],
   "source": [
    "string_to_int={ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string={i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode=lambda s:[string_to_int[c] for c in s]\n",
    "decode=lambda l:''.join([int_to_string[i] for i in l])\n",
    "\n",
    "print(encode('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bc91fc-b1db-45fb-bdad-ceccb4b82998",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.tensor(encode(text),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91368d0-e52c-492f-b28b-029bd2c03bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
      "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26,\n",
      "        49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,\n",
      "         0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1,\n",
      "        47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1,\n",
      "        36, 25, 38, 28,  1, 39, 30,  1, 39, 50])\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822df613-727c-40a6-849c-cce9d49cb98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[45, 67, 56, 65, 58,  1, 32, 58],\n",
      "        [55, 58, 56, 54, 66, 58,  1, 73],\n",
      "        [56, 74, 57, 57, 65, 58, 57,  1],\n",
      "        [73, 68,  1, 73, 58, 65, 65,  0]])\n",
      "targets:\n",
      "tensor([[67, 56, 65, 58,  1, 32, 58, 67],\n",
      "        [58, 56, 54, 66, 58,  1, 73, 61],\n",
      "        [74, 57, 57, 65, 58, 57,  1, 74],\n",
      "        [68,  1, 73, 58, 65, 65,  0, 73]])\n"
     ]
    }
   ],
   "source": [
    "n=int(0.8*(len(data)))\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "# print(x.shape)\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2525ab31-0f5f-4b07-b7ba-4100fa43d29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([80]) target is tensor(1)\n",
      "when input is tensor([80,  1]) target is tensor(1)\n",
      "when input is tensor([80,  1,  1]) target is tensor(28)\n",
      "when input is tensor([80,  1,  1, 28]) target is tensor(39)\n",
      "when input is tensor([80,  1,  1, 28, 39]) target is tensor(42)\n",
      "when input is tensor([80,  1,  1, 28, 39, 42]) target is tensor(39)\n",
      "when input is tensor([80,  1,  1, 28, 39, 42, 39]) target is tensor(44)\n",
      "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44]) target is tensor(32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    print('when input is',context,'target is',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b7d01b-9d32-45fb-bb4c-c00fe4724e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k0Qg(O(c]!Bu_O2:_QE,vZot5ZnKArjTXIsRqOSLdupVPYOD(pmT.B)KAP_N*HG_N*61c1l'SobNmZaT.bvSeMNFcb: GY6tPY.]uv;Bz37NoU0lSM]. -N;F)Zm\"] ZcBz&:_JOLu﻿q.:)iRt\"KlP8bFeJ7b&'L'VciRJTlIgZxDc?Hd]]6uhlYuFffFiR4gWEiL;F3C.zyh-YXmsRq29P\"yy6b.]Cm]7xw.'nLq0HbXd7ddq*mgI?CYdCviNqhjE9nZ9cPbWs1iKr1Nf)FiRiu);TZzd&eW67k09L.E9me3WGDLIg(F]vK \n",
      "gSmZaDU)\n",
      "8]Hwe3-jx\"] hI5Y7:FW4Nf[U!xDv7sgI-EilZ_w3TfwaRytaa5G]X79g(FWup3D sjTR_w8]A&]T AhRq2xD,VGHPvXr)OHmV.OSrfjXiKwWfNm(UEDx1\n",
      "a,&UCY;c:I*HQke6bK?:* bG﻿j_nWjNJ8;Y\"bK2L'l&fPrv;A.[\n",
      "G0*LDl\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1007a99-27e5-4621-ba20-f493f9fff4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "965bd986-1649-4cab-ac50-cf46de833075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 2.472, val loss: 2.526\n",
      "step: 250, train loss: 2.483, val loss: 2.582\n",
      "step: 500, train loss: 2.484, val loss: 2.577\n",
      "step: 750, train loss: 2.476, val loss: 2.572\n",
      "2.419823169708252\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # sample a batch of data|\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f47a7c5-f263-4aa7-a6f1-bfbc50e0777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "heare The ntoorow I chenot OFivone yotheredsurenthavebeyor whad thed thtoul VAlyome st Dofizmir wisothe Pr ie gre wed r.\"Yom that id andileappele beead appila thed, id d s athierrr ery.\n",
      "\n",
      "ha we, m\n",
      "s d tedeilll irotomilewand thed t fustowa Zeat g thed ad flest tun bambed wop thedim yoy onalag.\n",
      "toopony ino, to blounthodasoune\n",
      "\"\n",
      "\"\n",
      "\" theenor a\n",
      "\"Ne ofur. k wanghe, beil\n",
      "I au inghin ad t \"Ille.\n",
      "\n",
      "se t abuind we\n",
      "\n",
      "ce thand t ke.\" he\n",
      "\n",
      "\"We sngh thas, tifo OThe, theenero whive s, k bed ghe; a faingitotoffande\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b525d2a-66f1-4a67-938c-68b4bab3c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tey sn Ilyeckeyecoraiflve,\" cotrral h bon'salofty a pedencat; tthare.\n",
      "if fll I bed ronthow tongineaisoawe jus Ze po ainy s thigl tinke sa hiran me bullalyore Douithe beried tf ar buigr heane wn Zeryeanganan way\n",
      "\"\n",
      "a ous frer shed\n",
      "\n",
      "\"Thaland lupotod\n",
      "\n",
      "t\n",
      "\n",
      "Tha knad ned crchiey.\"THAr iss,\n",
      "\n",
      "ow thows hayoves\n",
      "he mu he burnyogo haited \"Wiem rero be t AL adedrc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cuaso an are but the\n",
      "\n",
      "mabulkelylidin sthenyot a ibere, g cauis. askedered y they a t treang Jid Doronore thinete thenewin atithad f the tctem o\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e5fba-1cbc-40f0-b706-33ac99e1cf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
